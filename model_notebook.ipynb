{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f059832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option('max_rows', 100)\n",
    "\n",
    "from prepare import wrangle_data, split_data\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4cc5cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, sale_df, rent_df = wrangle_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2790011",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'newconstructionyn'\n",
    "positive = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7409e32",
   "metadata": {},
   "source": [
    "## Prep for Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dd6d0e",
   "metadata": {},
   "source": [
    "### Drop columns not used in modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "467714a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "                'address_id',               # unique identifier not useful\n",
    "                'listingcontractdate',      # we'll use engineered date features instead\n",
    "                'originallistprice',         # we'll use the scaled prices instead\n",
    "                'originallistprice_persqft', # we'll use the scaled prices instead\n",
    "                'originallistprice_scaled', # we'll use the persqft prices instead\n",
    "                ]\n",
    "\n",
    "df = df.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385da04c",
   "metadata": {},
   "source": [
    "### Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1440207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(df):\n",
    "    '''\n",
    "    This function takes in our dataset and encodes a given set of \n",
    "    categorical features using pandas one-hot encoder. It drops\n",
    "    the original un-encoded columns and returns the df. \n",
    "    '''\n",
    "    # categorical variables (that aren't already binary True/False)\n",
    "    cols_to_encode = [\n",
    "                      'propertytype', \n",
    "                      'propertysubtype', \n",
    "                     ]\n",
    "    \n",
    "    # create encoded column for each feature\n",
    "    for col in cols_to_encode:\n",
    "        dummy_df = pd.get_dummies(df[col],\n",
    "                                  prefix=df[col].name,\n",
    "                                  drop_first=True,\n",
    "                                  dummy_na=False)\n",
    "        # add encoded column to df\n",
    "        df = pd.concat([df, dummy_df], axis=1)\n",
    "        # drop original column\n",
    "        df = df.drop(columns=col)\n",
    "        \n",
    "    return df\n",
    "\n",
    "df = encode_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e3d487",
   "metadata": {},
   "source": [
    "### Turn boolean columns into 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22a7244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bools(df):\n",
    "    '''\n",
    "    This function takes in our dataset and converts all boolean columns to 1 or 0\n",
    "    numeric datatypes, then returns the df.\n",
    "    '''\n",
    "    # identify boolean columns\n",
    "    bools = [col for col in df.columns if df[col].dtype == 'bool']\n",
    "    # convert to 1 or 0\n",
    "    for col in bools:\n",
    "        df[col] = df[col].map({True: 1, False: 0})\n",
    "    return df\n",
    "\n",
    "df = convert_bools(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8361f703",
   "metadata": {},
   "source": [
    "### Split the Data: Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cbf2594",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db2a83d",
   "metadata": {},
   "source": [
    "### Scale quantitative variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0737a2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(train, test, scaler_type=MinMaxScaler()):\n",
    "    '''\n",
    "    This takes in the train and test dataframes. \n",
    "\n",
    "    It then fits a scaler object to the train sample based on the given sample_type, applies that\n",
    "    scaler to the trainand test samples, and appends the new scaled data to the \n",
    "    dataframes as additional columns with the prefix 'scaled_'. \n",
    "\n",
    "    train and test dataframes are returned, in that order. \n",
    "    '''\n",
    "    # identify quantitative features to scale (that aren't already scaled)\n",
    "    cols_to_scale = [\n",
    "                     'lotsizearea', \n",
    "                     'bedroomstotal', \n",
    "                     'bathroomstotalinteger',\n",
    "                     'bathroomsfull',\n",
    "                     'bathroomshalf', \n",
    "                     'livingarea',\n",
    "                     'stories', \n",
    "                     'yearbuilt',\n",
    "                     'years_since_build', \n",
    "                     'garage_size', \n",
    "                     'central_cooling_units', \n",
    "                     'windowwall_cooling_units',\n",
    "                     'listing_month',\n",
    "                     'listing_dayofmonth', \n",
    "                     'listing_dayofweek'\n",
    "                    ]\n",
    "    \n",
    "    # establish empty dataframes for storing scaled dataset\n",
    "    train_scaled = pd.DataFrame(index=train.index)\n",
    "    test_scaled = pd.DataFrame(index=test.index)\n",
    "    \n",
    "    # screate and fit the scaler\n",
    "    scaler = scaler_type.fit(train[cols_to_scale])\n",
    "    \n",
    "    # adding scaled features to scaled dataframes\n",
    "    train_scaled[cols_to_scale] = scaler.transform(train[cols_to_scale])\n",
    "    test_scaled[cols_to_scale] = scaler.transform(test[cols_to_scale])\n",
    "    \n",
    "    # add 'scaled' prefix to columns\n",
    "    for feature in cols_to_scale:\n",
    "        train_scaled = train_scaled.rename(columns={feature: f'scaled_{feature}'})\n",
    "        test_scaled = test_scaled.rename(columns={feature: f'scaled_{feature}'})\n",
    "        \n",
    "    # concat scaled feature columns to original train and test df's\n",
    "    train = pd.concat([train, train_scaled], axis=1)\n",
    "    test = pd.concat([test, test_scaled], axis=1)\n",
    "    \n",
    "    # drop the original columns\n",
    "    train = train.drop(columns=cols_to_scale)\n",
    "    test = test.drop(columns=cols_to_scale)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "train, test = scale_data(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33a0bc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3002 entries, 1931 to 1859\n",
      "Data columns (total 65 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   garageyn                                3002 non-null   int64  \n",
      " 1   newconstructionyn                       3002 non-null   int64  \n",
      " 2   listed_on_weekend                       3002 non-null   int64  \n",
      " 3   previously_listed                       3002 non-null   int64  \n",
      " 4   built_last_two_years                    3002 non-null   int64  \n",
      " 5   parkingfeatures_attached                3002 non-null   int64  \n",
      " 6   parkingfeatures_detached                3002 non-null   int64  \n",
      " 7   parkingfeatures_oversized               3002 non-null   int64  \n",
      " 8   parkingfeatures_converted               3002 non-null   int64  \n",
      " 9   parkingfeatures_sideentry               3002 non-null   int64  \n",
      " 10  parkingfeatures_rearentry               3002 non-null   int64  \n",
      " 11  parkingfeatures_tandem                  3002 non-null   int64  \n",
      " 12  parkingfeatures_golfcart                3002 non-null   int64  \n",
      " 13  heating_central                         3002 non-null   int64  \n",
      " 14  heating_naturalgas                      3002 non-null   int64  \n",
      " 15  heating_electric                        3002 non-null   int64  \n",
      " 16  heating_2units                          3002 non-null   int64  \n",
      " 17  heating_heatpump                        3002 non-null   int64  \n",
      " 18  heating_1unit                           3002 non-null   int64  \n",
      " 19  heating_zoned                           3002 non-null   int64  \n",
      " 20  heating_other                           3002 non-null   int64  \n",
      " 21  heating_floorfurnace                    3002 non-null   int64  \n",
      " 22  heating_solar                           3002 non-null   int64  \n",
      " 23  heating_propaneowned                    3002 non-null   int64  \n",
      " 24  heating_none                            3002 non-null   int64  \n",
      " 25  heating_windowunit                      3002 non-null   int64  \n",
      " 26  cooling_central                         3002 non-null   int64  \n",
      " 27  cooling_windowwall                      3002 non-null   int64  \n",
      " 28  cooling_heatpump                        3002 non-null   int64  \n",
      " 29  cooling_zoned                           3002 non-null   int64  \n",
      " 30  archstyle_traditional                   3002 non-null   int64  \n",
      " 31  archstyle_contemporary                  3002 non-null   int64  \n",
      " 32  archstyle_splitlevel                    3002 non-null   int64  \n",
      " 33  archstyle_ranch                         3002 non-null   int64  \n",
      " 34  archstyle_texashillcountry              3002 non-null   int64  \n",
      " 35  archstyle_craftsman                     3002 non-null   int64  \n",
      " 36  archstyle_other                         3002 non-null   int64  \n",
      " 37  archstyle_colonial                      3002 non-null   int64  \n",
      " 38  archstyle_spanish                       3002 non-null   int64  \n",
      " 39  archstyle_manufacturedhome-singlewide   3002 non-null   int64  \n",
      " 40  archstyle_a-frame                       3002 non-null   int64  \n",
      " 41  lotsizearea_listed_negative             3002 non-null   int64  \n",
      " 42  lotsizearea_small                       3002 non-null   int64  \n",
      " 43  originallistprice_persqft_scaled        3002 non-null   float64\n",
      " 44  propertytype_Residential Rental         3002 non-null   uint8  \n",
      " 45  propertysubtype_Condominium             3002 non-null   uint8  \n",
      " 46  propertysubtype_Duplex                  3002 non-null   uint8  \n",
      " 47  propertysubtype_Manufactured Home       3002 non-null   uint8  \n",
      " 48  propertysubtype_Single Family Detached  3002 non-null   uint8  \n",
      " 49  propertysubtype_Townhouse               3002 non-null   uint8  \n",
      " 50  scaled_lotsizearea                      3002 non-null   float64\n",
      " 51  scaled_bedroomstotal                    3002 non-null   float64\n",
      " 52  scaled_bathroomstotalinteger            3002 non-null   float64\n",
      " 53  scaled_bathroomsfull                    3002 non-null   float64\n",
      " 54  scaled_bathroomshalf                    3002 non-null   float64\n",
      " 55  scaled_livingarea                       3002 non-null   float64\n",
      " 56  scaled_stories                          3002 non-null   float64\n",
      " 57  scaled_yearbuilt                        3002 non-null   float64\n",
      " 58  scaled_years_since_build                3002 non-null   float64\n",
      " 59  scaled_garage_size                      3002 non-null   float64\n",
      " 60  scaled_central_cooling_units            3002 non-null   float64\n",
      " 61  scaled_windowwall_cooling_units         3002 non-null   float64\n",
      " 62  scaled_listing_month                    3002 non-null   float64\n",
      " 63  scaled_listing_dayofmonth               3002 non-null   float64\n",
      " 64  scaled_listing_dayofweek                3002 non-null   float64\n",
      "dtypes: float64(16), int64(43), uint8(6)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5c710a",
   "metadata": {},
   "source": [
    "## Baseline Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8104e7",
   "metadata": {},
   "source": [
    "#### A simple baseline - predicting the most common class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942cb0dd",
   "metadata": {},
   "source": [
    "Since the majority of properties are not new construction, our simplest baseline would be to predict 0 for each property. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a32ff8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_baseline_1(train,\n",
    "                   target,\n",
    "                   positive,\n",
    "                   model_number,\n",
    "                   model_info,\n",
    "                   model_results):\n",
    "    '''\n",
    "    This function takes in the train sample, the target variable label, the positive condition label,\n",
    "    an initialized model_number variable, as well as model_info and model_results dataframes dataframes that will be used for \n",
    "    storing information about the models. It then performs the operations necessary for making baseline predictions\n",
    "    on our dataset, and stores information about our baseline model in the model_info and model_results dataframes. \n",
    "    (i.e. predicts the most common class)\n",
    "    The model_number, model_info, and model_results variables are returned (in that order). \n",
    "    '''\n",
    "\n",
    "    # separate each sample into x (features) and y (target)\n",
    "    x_train = train.drop(columns=target)\n",
    "    y_train = train[target]\n",
    "\n",
    "\n",
    "    # store baseline metrics\n",
    "\n",
    "    # identify model number\n",
    "    model_number = 'baseline_1'\n",
    "    #identify model type\n",
    "    model_type = 'baseline_1'\n",
    "\n",
    "    # store info about the model\n",
    "\n",
    "    # create a dictionary containing model number and model type\n",
    "    dct = {'model_number': model_number,\n",
    "           'model_type': model_type}\n",
    "    # append that dictionary to the model_info dataframe\n",
    "    model_info = model_info.append(dct, ignore_index=True)\n",
    "\n",
    "    # establish baseline predictions for train sample\n",
    "    y_pred = pd.Series([train[target].mode()[0]]).repeat(len(train))\n",
    "\n",
    "    # get metrics\n",
    "\n",
    "    # create dictionaries for each metric type for the train sample and append those dictionaries to the model_results dataframe\n",
    "    dct = {'model_number': model_number, \n",
    "           'metric_type': 'accuracy',\n",
    "           'score': sk.metrics.accuracy_score(y_train, y_pred)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    dct = {'model_number': model_number, \n",
    "           'metric_type': 'precision',\n",
    "           'score': sk.metrics.precision_score(y_train, y_pred, pos_label=positive)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    dct = {'model_number': model_number, \n",
    "           'metric_type': 'recall',\n",
    "           'score': sk.metrics.recall_score(y_train, y_pred, pos_label=positive)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    dct = {'model_number': model_number, \n",
    "           'metric_type': 'f1_score',\n",
    "           'score': sk.metrics.f1_score(y_train, y_pred, pos_label=positive)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    # set the model number to from 'baseline' to 0 \n",
    "    model_number = 0\n",
    "    \n",
    "    return model_number, model_info, model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40a7c5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the infrastructure to store information about our models\n",
    "model_number = 0\n",
    "model_info = pd.DataFrame()\n",
    "model_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2ac4797",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_number, model_info, model_results = run_baseline_1(train, target, positive,\n",
    "                                                         model_number, model_info, model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a577d4ee",
   "metadata": {},
   "source": [
    "#### An alternative baseline - predicting the positive class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3504d2a3",
   "metadata": {},
   "source": [
    "However, if our goal is to maximize recall, i.e. identify as many new construction as possible, a more reasonable baseline might be to treat all properties as if they are new construction (i.e. always predict 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e714613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_baseline_2(train,\n",
    "                   target,\n",
    "                   positive,\n",
    "                   model_number,\n",
    "                   model_info,\n",
    "                   model_results):\n",
    "    '''\n",
    "    This function takes in the train sample, the target variable label, the positive condition label,\n",
    "    an initialized model_number variable, as well as model_info and model_results dataframes dataframes that will be used for \n",
    "    storing information about the models. It then performs the operations necessary for making baseline predictions\n",
    "    on our dataset, and stores information about our baseline model in the model_info and model_results dataframes. \n",
    "    The model_number, model_info, and model_results variables are returned (in that order). \n",
    "    \n",
    "    For this alternative baseline, we will maximize recall by always predicting 1.\n",
    "    '''\n",
    "\n",
    "    # separate each sample into x (features) and y (target)\n",
    "    x_train = train.drop(columns=target)\n",
    "    y_train = train[target]\n",
    "\n",
    "    # store baseline metrics\n",
    "\n",
    "    # identify model number\n",
    "    model_number = 'baseline_2'\n",
    "    #identify model type\n",
    "    model_type = 'baseline_2'\n",
    "\n",
    "    # store info about the model\n",
    "\n",
    "    # create a dictionary containing model number and model type\n",
    "    dct = {'model_number': model_number,\n",
    "           'model_type': model_type}\n",
    "    # append that dictionary to the model_info dataframe\n",
    "    model_info = model_info.append(dct, ignore_index=True)\n",
    "\n",
    "    # establish baseline predictions for train sample\n",
    "    y_pred = pd.Series(1).repeat(len(train))\n",
    "\n",
    "    # get metrics\n",
    "\n",
    "    # create dictionaries for each metric type for the train sample and append those dictionaries to the model_results dataframe\n",
    "    dct = {'model_number': model_number, \n",
    "           'metric_type': 'accuracy',\n",
    "           'score': sk.metrics.accuracy_score(y_train, y_pred)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    dct = {'model_number': model_number, \n",
    "           'metric_type': 'precision',\n",
    "           'score': sk.metrics.precision_score(y_train, y_pred, pos_label=positive)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    dct = {'model_number': model_number, \n",
    "           'metric_type': 'recall',\n",
    "           'score': sk.metrics.recall_score(y_train, y_pred, pos_label=positive)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    dct = {'model_number': model_number, \n",
    "           'metric_type': 'f1_score',\n",
    "           'score': sk.metrics.f1_score(y_train, y_pred, pos_label=positive)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    # set the model number to from 'baseline' to 0 \n",
    "    model_number = 0\n",
    "    \n",
    "    return model_number, model_info, model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90fee987",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_number, model_info, model_results = run_baseline_2(train, target, positive,\n",
    "                                                         model_number, model_info, model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef2e9ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>metric_type</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline_1</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.792472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline_1</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baseline_1</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseline_1</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline_2</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.207528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>baseline_2</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.207528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>baseline_2</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>baseline_2</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.343724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_number metric_type     score\n",
       "0   baseline_1    accuracy  0.792472\n",
       "1   baseline_1   precision  0.000000\n",
       "2   baseline_1      recall  0.000000\n",
       "3   baseline_1    f1_score  0.000000\n",
       "4   baseline_2    accuracy  0.207528\n",
       "5   baseline_2   precision  0.207528\n",
       "6   baseline_2      recall  1.000000\n",
       "7   baseline_2    f1_score  0.343724"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0844fbc",
   "metadata": {},
   "source": [
    "## An Intuitive Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd80062",
   "metadata": {},
   "source": [
    "#### Using the most intuitive way of determining new construction as a more effective baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1fdbaa",
   "metadata": {},
   "source": [
    "Exploration found that our most reliable feature is whether the build year of the property is within two calendar years of the listing date. This is also very intuitive - any reasonable person looking at a listing and trying to guess whether it was new construction would look for a recent build year. If our eventual model cannot predict more reliably than that, it will not be of much use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "014a6515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_1(train,\n",
    "                target,\n",
    "                positive,\n",
    "                model_number,\n",
    "                model_info,\n",
    "                model_results):\n",
    "    '''\n",
    "    This function predicts whether a property is new construction based only on whether the build year is within\n",
    "    two calendar years of the listing. This will create a more effective and useful baseline for which to compare\n",
    "    future, more complex models. \n",
    "    \n",
    "    This function takes in the train sample, the target variable label, the positive condition label,\n",
    "    as well as the model_number variable and model_info and model_results dataframes. It then updates and returns\n",
    "    the model_number, model_info, and model_results variables after creating and storing info about the model \n",
    "    described above.\n",
    "    '''\n",
    "\n",
    "    # separate each sample into x (features) and y (target)\n",
    "    x_train = train.drop(columns=target)\n",
    "    y_train = train[target]\n",
    "\n",
    "    # identify model number\n",
    "    model_number = 1\n",
    "    #identify model type\n",
    "    model_type = 'simple build year'\n",
    "\n",
    "    # store info about the model\n",
    "\n",
    "    # create a dictionary containing model number and model type\n",
    "    dct = {'model_number': model_number,\n",
    "           'model_type': model_type}\n",
    "    # append that dictionary to the model_info dataframe\n",
    "    model_info = model_info.append(dct, ignore_index=True)\n",
    "\n",
    "    # establish predictions for train sample\n",
    "    y_pred = train.built_last_two_years\n",
    "\n",
    "    # get metrics\n",
    "\n",
    "    # create dictionaries for each metric type for the train sample and append those dictionaries to the model_results dataframe\n",
    "    dct = {'model_number': model_number, \n",
    "           'metric_type': 'accuracy',\n",
    "           'score': sk.metrics.accuracy_score(y_train, y_pred)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    dct = {'model_number': model_number, \n",
    "           'metric_type': 'precision',\n",
    "           'score': sk.metrics.precision_score(y_train, y_pred, pos_label=positive)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    dct = {'model_number': model_number, \n",
    "           'metric_type': 'recall',\n",
    "           'score': sk.metrics.recall_score(y_train, y_pred, pos_label=positive)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    dct = {'model_number': model_number, \n",
    "           'metric_type': 'f1_score',\n",
    "           'score': sk.metrics.f1_score(y_train, y_pred, pos_label=positive)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "    \n",
    "    return model_number, model_info, model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b8711ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_number, model_info, model_results = run_model_1(train, target, positive,\n",
    "                                                      model_number, model_info, model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9226c565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_model_results(model_results):\n",
    "    '''\n",
    "    This function takes in the model_results dataframe. This is a dataframe in tidy data format \n",
    "    containing the following information for each model created in the project:\n",
    "    - model number\n",
    "    - metric type (accuracy, precision, recall, f1 score)\n",
    "    - sample type (train, validate)\n",
    "    - score (the score for the given metric and sample types)\n",
    "    The function returns a pivot table of those values for easy comparison of models, metrics, and samples. \n",
    "    '''\n",
    "    # create a pivot table of the model_results dataframe\n",
    "    # establish columns as the model_number, with index as metric_type, and values as score\n",
    "    # the aggfunc uses a lambda to return each individual score without any aggregation applied\n",
    "    return model_results.pivot_table(columns='model_number', \n",
    "                                     index=('metric_type'), \n",
    "                                     values='score',\n",
    "                                     aggfunc=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bc7cc3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>metric_type</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline_1</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.792472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline_1</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baseline_1</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseline_1</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline_2</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.207528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>baseline_2</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.207528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>baseline_2</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>baseline_2</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.343724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.974017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.901325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.982343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.940092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_number metric_type     score\n",
       "0    baseline_1    accuracy  0.792472\n",
       "1    baseline_1   precision  0.000000\n",
       "2    baseline_1      recall  0.000000\n",
       "3    baseline_1    f1_score  0.000000\n",
       "4    baseline_2    accuracy  0.207528\n",
       "5    baseline_2   precision  0.207528\n",
       "6    baseline_2      recall  1.000000\n",
       "7    baseline_2    f1_score  0.343724\n",
       "8             1    accuracy  0.974017\n",
       "9             1   precision  0.901325\n",
       "10            1      recall  0.982343\n",
       "11            1    f1_score  0.940092"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d57781a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric_type</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.974017</td>\n",
       "      <td>0.940092</td>\n",
       "      <td>0.901325</td>\n",
       "      <td>0.982343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline_1</th>\n",
       "      <td>0.792472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline_2</th>\n",
       "      <td>0.207528</td>\n",
       "      <td>0.343724</td>\n",
       "      <td>0.207528</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric_type   accuracy  f1_score  precision    recall\n",
       "model_number                                         \n",
       "1             0.974017  0.940092   0.901325  0.982343\n",
       "baseline_1    0.792472  0.000000   0.000000  0.000000\n",
       "baseline_2    0.207528  0.343724   0.207528  1.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_model_results(model_results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cc5c50",
   "metadata": {},
   "source": [
    "## ML Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e456a3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this first iteration we will use only those which were observed to be potentially useful\n",
    "# during exploration\n",
    "features = ['built_last_two_years',\n",
    "             'previously_listed',\n",
    "             'scaled_stories',\n",
    "             'cooling_windowwall',\n",
    "             'originallistprice_persqft_scaled'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a174982",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c85f934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(train, target, features):\n",
    "    # split dataset into x (features) and y (target)\n",
    "    x_train = train[features]\n",
    "    y_train = train[target]\n",
    "\n",
    "    # identify model_type\n",
    "    model_type = 'decision tree'\n",
    "\n",
    "    # set hyperparameter ranges\n",
    "    parameter_space = {'max_depth': [2,3,4,5,6,7]}\n",
    "\n",
    "    # create the classifier\n",
    "    clf = DecisionTreeClassifier()\n",
    "\n",
    "    # define scoring methods\n",
    "    scoring = {'recall': make_scorer(sk.metrics.accuracy_score),\n",
    "               'precision': make_scorer(sk.metrics.precision_score),\n",
    "               'accuracy': make_scorer(sk.metrics.accuracy_score),\n",
    "               'f1_score': make_scorer(sk.metrics.f1_score)}\n",
    "\n",
    "    # create and fit the GridSearchCV object\n",
    "    grid = GridSearchCV(clf, parameter_space, cv=5, \n",
    "                        scoring=scoring,\n",
    "                        refit='recall')\n",
    "    grid.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "    # get results and store as dataframe\n",
    "\n",
    "    results = grid.cv_results_\n",
    "\n",
    "    params = results['params']\n",
    "    accuracy = results['mean_test_accuracy'] \n",
    "    recall = results['mean_test_recall']\n",
    "    precision = results['mean_test_precision']\n",
    "    F1_score = results['mean_test_f1_score']\n",
    "\n",
    "    for par, acc, rec, prec, f1 in zip(params, accuracy, recall, precision, F1_score):\n",
    "        par['model_type'] = model_type\n",
    "        par['features'] = features\n",
    "        par['accuracy'] = acc\n",
    "        par['recall'] = rec\n",
    "        par['precision'] = prec\n",
    "        par['F1_score'] = f1\n",
    "\n",
    "    decision_tree_results = pd.DataFrame(params)\n",
    "    \n",
    "    return decision_tree_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20a046ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>model_type</th>\n",
       "      <th>features</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>decision tree</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.974016</td>\n",
       "      <td>0.974016</td>\n",
       "      <td>0.901575</td>\n",
       "      <td>0.940145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>decision tree</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.974682</td>\n",
       "      <td>0.974682</td>\n",
       "      <td>0.905698</td>\n",
       "      <td>0.941562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>decision tree</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.975348</td>\n",
       "      <td>0.975348</td>\n",
       "      <td>0.910573</td>\n",
       "      <td>0.942777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>decision tree</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.975015</td>\n",
       "      <td>0.975015</td>\n",
       "      <td>0.910410</td>\n",
       "      <td>0.941951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>decision tree</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.973683</td>\n",
       "      <td>0.973683</td>\n",
       "      <td>0.908771</td>\n",
       "      <td>0.938782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>decision tree</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.973016</td>\n",
       "      <td>0.973016</td>\n",
       "      <td>0.908477</td>\n",
       "      <td>0.937122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth     model_type  \\\n",
       "0          2  decision tree   \n",
       "1          3  decision tree   \n",
       "2          4  decision tree   \n",
       "3          5  decision tree   \n",
       "4          6  decision tree   \n",
       "5          7  decision tree   \n",
       "\n",
       "                                            features  accuracy    recall  \\\n",
       "0  [built_last_two_years, previously_listed, scal...  0.974016  0.974016   \n",
       "1  [built_last_two_years, previously_listed, scal...  0.974682  0.974682   \n",
       "2  [built_last_two_years, previously_listed, scal...  0.975348  0.975348   \n",
       "3  [built_last_two_years, previously_listed, scal...  0.975015  0.975015   \n",
       "4  [built_last_two_years, previously_listed, scal...  0.973683  0.973683   \n",
       "5  [built_last_two_years, previously_listed, scal...  0.973016  0.973016   \n",
       "\n",
       "   precision  F1_score  \n",
       "0   0.901575  0.940145  \n",
       "1   0.905698  0.941562  \n",
       "2   0.910573  0.942777  \n",
       "3   0.910410  0.941951  \n",
       "4   0.908771  0.938782  \n",
       "5   0.908477  0.937122  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree(train, target, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae92b8c0",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a011297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(train, target, features):\n",
    "    # split dataset into x (features) and y (target)\n",
    "    x_train = train[features]\n",
    "    y_train = train[target]\n",
    "\n",
    "    # identify model_type\n",
    "    model_type = 'random forest'\n",
    "\n",
    "    # set hyperparameter ranges\n",
    "    parameter_space = {'max_depth': [2,3,4,5,6,7],\n",
    "                       'min_samples_leaf': [2,3,4]}\n",
    "\n",
    "    # create the classifier\n",
    "    clf = RandomForestClassifier()\n",
    "\n",
    "    # define scoring methods\n",
    "    scoring = {'recall': make_scorer(sk.metrics.accuracy_score),\n",
    "               'precision': make_scorer(sk.metrics.precision_score),\n",
    "               'accuracy': make_scorer(sk.metrics.accuracy_score),\n",
    "               'f1_score': make_scorer(sk.metrics.f1_score)}\n",
    "\n",
    "    # create and fit the GridSearchCV object\n",
    "    grid = GridSearchCV(clf, parameter_space, cv=5, \n",
    "                        scoring=scoring,\n",
    "                        refit='recall')\n",
    "    grid.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "    # get results and store as dataframe\n",
    "\n",
    "    results = grid.cv_results_\n",
    "\n",
    "    params = results['params']\n",
    "    accuracy = results['mean_test_accuracy'] \n",
    "    recall = results['mean_test_recall']\n",
    "    precision = results['mean_test_precision']\n",
    "    F1_score = results['mean_test_f1_score']\n",
    "\n",
    "    for par, acc, rec, prec, f1 in zip(params, accuracy, recall, precision, F1_score):\n",
    "        par['model_type'] = model_type\n",
    "        par['features'] = features\n",
    "        par['accuracy'] = acc\n",
    "        par['recall'] = rec\n",
    "        par['precision'] = prec\n",
    "        par['F1_score'] = f1\n",
    "\n",
    "    random_forest_results = pd.DataFrame(params)\n",
    "    \n",
    "    return random_forest_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb8fa0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>model_type</th>\n",
       "      <th>features</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>random forest</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.974016</td>\n",
       "      <td>0.974016</td>\n",
       "      <td>0.901575</td>\n",
       "      <td>0.940145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>random forest</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.972019</td>\n",
       "      <td>0.972019</td>\n",
       "      <td>0.900865</td>\n",
       "      <td>0.935161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>random forest</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.970688</td>\n",
       "      <td>0.970688</td>\n",
       "      <td>0.900268</td>\n",
       "      <td>0.931818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>random forest</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.973350</td>\n",
       "      <td>0.973350</td>\n",
       "      <td>0.902464</td>\n",
       "      <td>0.938410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>random forest</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.973683</td>\n",
       "      <td>0.973683</td>\n",
       "      <td>0.902610</td>\n",
       "      <td>0.939236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>random forest</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.973350</td>\n",
       "      <td>0.973350</td>\n",
       "      <td>0.902464</td>\n",
       "      <td>0.938410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>random forest</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.973683</td>\n",
       "      <td>0.973683</td>\n",
       "      <td>0.903726</td>\n",
       "      <td>0.939112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>random forest</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.973350</td>\n",
       "      <td>0.973350</td>\n",
       "      <td>0.902464</td>\n",
       "      <td>0.938410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>random forest</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.973350</td>\n",
       "      <td>0.973350</td>\n",
       "      <td>0.902464</td>\n",
       "      <td>0.938410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>random forest</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.973350</td>\n",
       "      <td>0.973350</td>\n",
       "      <td>0.903717</td>\n",
       "      <td>0.938319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>random forest</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.973017</td>\n",
       "      <td>0.973017</td>\n",
       "      <td>0.902316</td>\n",
       "      <td>0.937577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>random forest</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.973017</td>\n",
       "      <td>0.973017</td>\n",
       "      <td>0.902316</td>\n",
       "      <td>0.937577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>random forest</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.974682</td>\n",
       "      <td>0.974682</td>\n",
       "      <td>0.909126</td>\n",
       "      <td>0.941231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>random forest</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.974016</td>\n",
       "      <td>0.974016</td>\n",
       "      <td>0.906584</td>\n",
       "      <td>0.939821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>random forest</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.973017</td>\n",
       "      <td>0.973017</td>\n",
       "      <td>0.902316</td>\n",
       "      <td>0.937577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>random forest</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.973683</td>\n",
       "      <td>0.973683</td>\n",
       "      <td>0.904979</td>\n",
       "      <td>0.939022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>random forest</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.973017</td>\n",
       "      <td>0.973017</td>\n",
       "      <td>0.902316</td>\n",
       "      <td>0.937577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>random forest</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.972351</td>\n",
       "      <td>0.972351</td>\n",
       "      <td>0.900824</td>\n",
       "      <td>0.936027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_samples_leaf     model_type  \\\n",
       "0           2                 2  random forest   \n",
       "1           2                 3  random forest   \n",
       "2           2                 4  random forest   \n",
       "3           3                 2  random forest   \n",
       "4           3                 3  random forest   \n",
       "5           3                 4  random forest   \n",
       "6           4                 2  random forest   \n",
       "7           4                 3  random forest   \n",
       "8           4                 4  random forest   \n",
       "9           5                 2  random forest   \n",
       "10          5                 3  random forest   \n",
       "11          5                 4  random forest   \n",
       "12          6                 2  random forest   \n",
       "13          6                 3  random forest   \n",
       "14          6                 4  random forest   \n",
       "15          7                 2  random forest   \n",
       "16          7                 3  random forest   \n",
       "17          7                 4  random forest   \n",
       "\n",
       "                                             features  accuracy    recall  \\\n",
       "0   [built_last_two_years, previously_listed, scal...  0.974016  0.974016   \n",
       "1   [built_last_two_years, previously_listed, scal...  0.972019  0.972019   \n",
       "2   [built_last_two_years, previously_listed, scal...  0.970688  0.970688   \n",
       "3   [built_last_two_years, previously_listed, scal...  0.973350  0.973350   \n",
       "4   [built_last_two_years, previously_listed, scal...  0.973683  0.973683   \n",
       "5   [built_last_two_years, previously_listed, scal...  0.973350  0.973350   \n",
       "6   [built_last_two_years, previously_listed, scal...  0.973683  0.973683   \n",
       "7   [built_last_two_years, previously_listed, scal...  0.973350  0.973350   \n",
       "8   [built_last_two_years, previously_listed, scal...  0.973350  0.973350   \n",
       "9   [built_last_two_years, previously_listed, scal...  0.973350  0.973350   \n",
       "10  [built_last_two_years, previously_listed, scal...  0.973017  0.973017   \n",
       "11  [built_last_two_years, previously_listed, scal...  0.973017  0.973017   \n",
       "12  [built_last_two_years, previously_listed, scal...  0.974682  0.974682   \n",
       "13  [built_last_two_years, previously_listed, scal...  0.974016  0.974016   \n",
       "14  [built_last_two_years, previously_listed, scal...  0.973017  0.973017   \n",
       "15  [built_last_two_years, previously_listed, scal...  0.973683  0.973683   \n",
       "16  [built_last_two_years, previously_listed, scal...  0.973017  0.973017   \n",
       "17  [built_last_two_years, previously_listed, scal...  0.972351  0.972351   \n",
       "\n",
       "    precision  F1_score  \n",
       "0    0.901575  0.940145  \n",
       "1    0.900865  0.935161  \n",
       "2    0.900268  0.931818  \n",
       "3    0.902464  0.938410  \n",
       "4    0.902610  0.939236  \n",
       "5    0.902464  0.938410  \n",
       "6    0.903726  0.939112  \n",
       "7    0.902464  0.938410  \n",
       "8    0.902464  0.938410  \n",
       "9    0.903717  0.938319  \n",
       "10   0.902316  0.937577  \n",
       "11   0.902316  0.937577  \n",
       "12   0.909126  0.941231  \n",
       "13   0.906584  0.939821  \n",
       "14   0.902316  0.937577  \n",
       "15   0.904979  0.939022  \n",
       "16   0.902316  0.937577  \n",
       "17   0.900824  0.936027  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest(train, target, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb00387",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b760e80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_regression(train, target, features):\n",
    "    # split dataset into x (features) and y (target)\n",
    "    x_train = train[features]\n",
    "    y_train = train[target]\n",
    "\n",
    "    # identify model_type\n",
    "    model_type = 'logistic regression'\n",
    "\n",
    "    # set hyperparameter ranges\n",
    "    parameter_space = {'C': [.001, .01, .1, 1, 10, 100, 1000]}\n",
    "\n",
    "    # create the classifier\n",
    "    clf = LogisticRegression()\n",
    "\n",
    "    # define scoring methods\n",
    "    scoring = {'recall': make_scorer(sk.metrics.accuracy_score),\n",
    "               'precision': make_scorer(sk.metrics.precision_score),\n",
    "               'accuracy': make_scorer(sk.metrics.accuracy_score),\n",
    "               'f1_score': make_scorer(sk.metrics.f1_score)}\n",
    "\n",
    "    # create and fit the GridSearchCV object\n",
    "    grid = GridSearchCV(clf, parameter_space, cv=5, \n",
    "                        scoring=scoring,\n",
    "                        refit='recall')\n",
    "    grid.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "    # get results and store as dataframe\n",
    "\n",
    "    results = grid.cv_results_\n",
    "\n",
    "    params = results['params']\n",
    "    accuracy = results['mean_test_accuracy'] \n",
    "    recall = results['mean_test_recall']\n",
    "    precision = results['mean_test_precision']\n",
    "    F1_score = results['mean_test_f1_score']\n",
    "\n",
    "    for par, acc, rec, prec, f1 in zip(params, accuracy, recall, precision, F1_score):\n",
    "        par['model_type'] = model_type\n",
    "        par['features'] = features\n",
    "        par['accuracy'] = acc\n",
    "        par['recall'] = rec\n",
    "        par['precision'] = prec\n",
    "        par['F1_score'] = f1\n",
    "\n",
    "    log_regression_results = pd.DataFrame(params)\n",
    "    \n",
    "    return log_regression_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08790452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>model_type</th>\n",
       "      <th>features</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.792472</td>\n",
       "      <td>0.792472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.971354</td>\n",
       "      <td>0.971354</td>\n",
       "      <td>0.911647</td>\n",
       "      <td>0.932610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.974016</td>\n",
       "      <td>0.974016</td>\n",
       "      <td>0.901575</td>\n",
       "      <td>0.940145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.974016</td>\n",
       "      <td>0.974016</td>\n",
       "      <td>0.901575</td>\n",
       "      <td>0.940145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.973683</td>\n",
       "      <td>0.973683</td>\n",
       "      <td>0.901425</td>\n",
       "      <td>0.939331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.973683</td>\n",
       "      <td>0.973683</td>\n",
       "      <td>0.901425</td>\n",
       "      <td>0.939331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000.000</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>[built_last_two_years, previously_listed, scal...</td>\n",
       "      <td>0.973683</td>\n",
       "      <td>0.973683</td>\n",
       "      <td>0.901425</td>\n",
       "      <td>0.939331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          C           model_type  \\\n",
       "0     0.001  logistic regression   \n",
       "1     0.010  logistic regression   \n",
       "2     0.100  logistic regression   \n",
       "3     1.000  logistic regression   \n",
       "4    10.000  logistic regression   \n",
       "5   100.000  logistic regression   \n",
       "6  1000.000  logistic regression   \n",
       "\n",
       "                                            features  accuracy    recall  \\\n",
       "0  [built_last_two_years, previously_listed, scal...  0.792472  0.792472   \n",
       "1  [built_last_two_years, previously_listed, scal...  0.971354  0.971354   \n",
       "2  [built_last_two_years, previously_listed, scal...  0.974016  0.974016   \n",
       "3  [built_last_two_years, previously_listed, scal...  0.974016  0.974016   \n",
       "4  [built_last_two_years, previously_listed, scal...  0.973683  0.973683   \n",
       "5  [built_last_two_years, previously_listed, scal...  0.973683  0.973683   \n",
       "6  [built_last_two_years, previously_listed, scal...  0.973683  0.973683   \n",
       "\n",
       "   precision  F1_score  \n",
       "0   0.000000  0.000000  \n",
       "1   0.911647  0.932610  \n",
       "2   0.901575  0.940145  \n",
       "3   0.901575  0.940145  \n",
       "4   0.901425  0.939331  \n",
       "5   0.901425  0.939331  \n",
       "6   0.901425  0.939331  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_regression(train, target, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3757a6b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
